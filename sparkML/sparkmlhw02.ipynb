{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sparkmlhw02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "#生成SparkSession实例\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local[*]\") \\\n",
    "     .appName(\"sparkmlhw02\") \\\n",
    "     .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+--------------------+--------------------+\n",
      "|myapp_id|typenameid|typename|          myapp_word|      myapp_word_all|\n",
      "+--------+----------+--------+--------------------+--------------------+\n",
      "| 1376533|         2|  action|game, android, world|game, android, wo...|\n",
      "| 1376542|         2|  action|                game|game, app, enjoy,...|\n",
      "| 1376603|         2|  action|run, tap, collect...|run, tap, collect...|\n",
      "| 1376792|         2|  action|                 run|run, ath, game, m...|\n",
      "| 1376941|         2|  action|fight, game, play...|fight, game, play...|\n",
      "+--------+----------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.csv(\"file:///home/ian/code/data/sparkml/doc_class.dat\", sep='|', header=True)\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(myapp_id='1376533', typenameid='2', typename='action', myapp_word='game, android, world', myapp_word_all='game, android, world, control, devic, experi, free, gameplay, play, screen, time, touch, war, action, addict, app, ath, attack, battl, challeng, collect, complet, descript, easi, enemi, enjoy, featur, fight, find, friend, fun, gamec, graphic, great, gun, high, kill, level, make, mission, mode, move, player, power, read, real, run, score, shoot, shooter, simpl, skill, sound, special, surviv, tap, uniqu, upgrad, weapon, zombi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('myapp_id', 'string'),\n",
       " ('typenameid', 'string'),\n",
       " ('typename', 'string'),\n",
       " ('myapp_word', 'string'),\n",
       " ('myapp_word_all', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myapp_id', 'typenameid', 'typename', 'myapp_word', 'myapp_word_all']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan csv [myapp_id#52,typenameid#53,typename#54,myapp_word#55,myapp_word_all#56] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/ian/code/data/sparkml/doc_class.dat], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<myapp_id:string,typenameid:string,typename:string,myapp_word:string,myapp_word_all:string>\n"
     ]
    }
   ],
   "source": [
    "df1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir('/tt123')#hdfs://h1:9200/ttl23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[myapp_id: string, typenameid: string, typename: string, myapp_word: string, myapp_word_all: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumnRenamed('typenameid','label')\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "df1 = df1.withColumn('label', col('label').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分训练集和测试集,会先打乱数据集\n",
    "train_set, test_set = df1.randomSplit([0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301051"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+--------------------+--------------------+\n",
      "|myapp_id|label|typename|          myapp_word|      myapp_word_all|\n",
      "+--------+-----+--------+--------------------+--------------------+\n",
      "| 1376501|    4|  arcade|level, game, app,...|level, game, app,...|\n",
      "| 1376513|    4|  arcade|           app, make|app, make, game, ...|\n",
      "| 1376533|    2|  action|game, android, world|game, android, wo...|\n",
      "| 1376542|    2|  action|                game|game, app, enjoy,...|\n",
      "| 1376565|    4|  arcade|          game, athi|game, athi, app, ...|\n",
      "+--------+-----+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(inputCol='myapp_word_all', outputCol='words')\n",
    "hashingTF = HashingTF(numFeatures=1000, inputCol='words', outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "model = pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+--------------------+----------+\n",
      "|myapp_id|label|typename|         probability|prediction|\n",
      "+--------+-----+--------+--------------------+----------+\n",
      "| 1376490|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1376579|    4|  arcade|[5.90032797772139...|       4.0|\n",
      "| 1376603|    2|  action|[2.05749718404754...|       2.0|\n",
      "| 1376684|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1376912|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1376983|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1377059|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1377084|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1377104|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1377220|    2|  action|[2.05749718404754...|       2.0|\n",
      "| 1377321|    2|  action|[2.05749718404754...|       2.0|\n",
      "| 1377943|    4|  arcade|[5.90032797772139...|       4.0|\n",
      "| 1378422|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1378849|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1379087|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1379297|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1379331|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1379486|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "| 1379509|    2|  action|[2.05749718404754...|       2.0|\n",
      "| 1379537|    4|  arcade|[6.67411865258183...|       4.0|\n",
      "+--------+-----+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = model.transform(test_set)\n",
    "p.select(\"myapp_id\",\"label\",\"typename\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存和加载\n",
    "model.save('file:///tmp/testModel')\n",
    "savedModel = PipelineModel.load('file:///tmp/testModel')\n",
    "pipeline.save('file:///tmp/pp')\n",
    "pp = Pipeline.load('file:///tmp/pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
