{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load pyspark08_df.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "@author:  'Administrator'\n",
    "@contact:  \n",
    "@time: \n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/python\n",
    "# encoding: utf-8\n",
    "# ================ 直接创建DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.shuffle.partitions\", 6)\n",
    "# ================直接创建==========================\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "# schemaPeople = sqlContext.createDataFrame(people)\n",
    "schemaPeople = spark.createDataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=25, name='Ankit'), Row(age=22, name='Jalfaizy')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ian/code/github/LSCJcourses/pysparkTJ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SepalLength: string (nullable = true)\n",
      " |-- SepalWidth: string (nullable = true)\n",
      " |-- PetalLength: string (nullable = true)\n",
      " |-- PetalWidth: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================从csv读取======================\n",
    "df = spark.read.format(\"csv\"). \\\n",
    "    option(\"header\", \"true\") \\\n",
    "    .load(\"file:////home/ian/code/github/LSCJcourses/pysparkTJ/iris.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|       Name|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "|        5.4|       3.9|        1.7|       0.4|Iris-setosa|\n",
      "|        4.6|       3.4|        1.4|       0.3|Iris-setosa|\n",
      "|        5.0|       3.4|        1.5|       0.2|Iris-setosa|\n",
      "|        4.4|       2.9|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.1|        1.5|       0.1|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Name']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+--------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|       Name|newWidth|\n",
      "+-----------+----------+-----------+----------+-----------+--------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|     7.0|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|     6.0|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|     6.4|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|     6.2|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|     7.2|\n",
      "+-----------+----------+-----------+----------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============增加一列(或者替换) withColumn===========\n",
    "# Column name which we want add /replace.\n",
    "# Expression on column.\n",
    "\n",
    "df.withColumn('newWidth',df.SepalWidth * 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|\n",
      "+-----------+----------+-----------+----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|\n",
      "|        4.9|       3.0|        1.4|       0.2|\n",
      "|        4.7|       3.2|        1.3|       0.2|\n",
      "|        4.6|       3.1|        1.5|       0.2|\n",
      "|        5.0|       3.6|        1.4|       0.2|\n",
      "+-----------+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========删除一列  drop=========================\n",
    "df.drop('Name').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|       SepalLength|         SepalWidth|       PetalLength|        PetalWidth|          Name|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               150|                150|               150|               150|           150|\n",
      "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          null|\n",
      "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================ 统计信息 describe================\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|          Name|\n",
      "+-------+--------------+\n",
      "|  count|           150|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|   Iris-setosa|\n",
      "|    max|Iris-virginica|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('Name').show()   #分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|       Name|SepalLength|\n",
      "+-----------+-----------+\n",
      "|Iris-setosa|        5.1|\n",
      "|Iris-setosa|        4.9|\n",
      "|Iris-setosa|        4.7|\n",
      "|Iris-setosa|        4.6|\n",
      "|Iris-setosa|        5.0|\n",
      "+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============提取部分列 select==============\n",
    "df.select('Name','SepalLength').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================基本统计功能 distinct count=====\n",
    "df.select('Name').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+------------------+\n",
      "|           Name|max(SepalLength)|   avg(SepalWidth)|\n",
      "+---------------+----------------+------------------+\n",
      "| Iris-virginica|             7.9|2.9739999999999998|\n",
      "|    Iris-setosa|             5.8|3.4180000000000006|\n",
      "|Iris-versicolor|             7.0|2.7700000000000005|\n",
      "+---------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分组统计 groupby(colname).agg({'col':'fun','col2':'fun2'})\n",
    "df.groupby('Name').agg({'SepalWidth':'mean','SepalLength':'max'}).show()\n",
    "# avg(), count(), countDistinct(), first(), kurtosis(): 峰度,\n",
    "# max(), mean(), min(), skewness(), stddev(), stddev_pop(),\n",
    "# stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(width_count=150, distinct_Name_count=3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义的汇总方法\n",
    "\n",
    "import pyspark.sql.functions as fn\n",
    "df.agg(fn.count('SepalWidth').alias('width_count'),\n",
    "       fn.countDistinct('Name').alias('distinct_Name_count')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================数据集拆成两部分 randomSplit ===========\n",
    "trainDF, testDF = df.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，只是按照要求的比例近似拆分，而不是严格按照比例拆分（150的0.6是90）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 100, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(),trainDF.count(),testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================采样数据 sample===========\n",
    "# withReplacement = True or False to select a observation with or without replacement.\n",
    "# fraction = x, where x = .5 shows that we want to have 50% data in sample DataFrame.\n",
    "# seed for reproduce the result\n",
    "sdf = df.sample(False,0.2,100)#无放回抽样 抽20%，100是一个随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看两个数据集在类别上的差异 subtract，确保训练数据集覆盖了所有分类\n",
    "\n",
    "diff_in_train_test = testDF.select('Name').subtract(trainDF.select('Name'))\n",
    "diff_in_train_test.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_in_train_test.count()#0 说明训练集和测试集覆盖的分类无差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       Name|\n",
      "+-----------+\n",
      "|Iris-setosa|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================== 综合案例，+ udf================\n",
    "# 测试数据集中有些类别在训练集中是不存在的，把这些数据集应该从测试集中删除\n",
    "trainDF,testDF = df.randomSplit([0.01,0.98])\n",
    "\n",
    "diff_in_train_test = testDF.select('Name').subtract(trainDF.select('Name')).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述说明测试集中有Iris-setosa这个分类，而训练集中没有。这会导致的一个直接后果就是：所训练的模型的预测结果中不会有Iris-setosa这个分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|Name_SepalLength|4.3|4.4|4.5|4.6|4.7|4.8|4.9|5.0|5.1|5.2|5.3|5.4|5.5|5.6|5.7|5.8|5.9|6.0|6.1|6.2|6.3|6.4|6.5|6.6|6.7|6.8|6.9|7.0|7.1|7.2|7.3|7.4|7.6|7.7|7.9|\n",
      "+----------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|  Iris-virginica|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  1|  1|  3|  1|  2|  2|  2|  6|  5|  4|  0|  5|  2|  3|  0|  1|  3|  1|  1|  1|  4|  1|\n",
      "|     Iris-setosa|  1|  3|  1|  4|  2|  5|  4|  8|  8|  3|  1|  5|  2|  0|  2|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "| Iris-versicolor|  0|  0|  0|  0|  0|  0|  1|  2|  1|  1|  0|  1|  5|  5|  5|  3|  2|  4|  4|  2|  3|  2|  1|  2|  3|  1|  1|  1|  0|  0|  0|  0|  0|  0|  0|\n",
      "+----------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================交叉表 crosstab=============\n",
    "df.crosstab('Name','SepalLength').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|       Name|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============sql 功能 ==============\n",
    "df.registerTempTable('train_table')\n",
    "spark.sql(\"select * from train_table limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先找到这些类，整理到一个列表\n",
    "\n",
    "not_exist_cats = testDF.select('Name').subtract(trainDF.select('Name')).distinct().rdd.map(lambda x :x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_exist_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个方法，用于检测\n",
    "def should_remove(x):\n",
    "    if x in not_exist_cats:\n",
    "        return \"-1\"\n",
    "    else :\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建udf，udf函数需要两个参数：\n",
    "# Function\n",
    "# Return type (in my case StringType())\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "check = udf(should_remove,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|           Name|       New_name|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|        4.3|       3.0|        1.1|       0.1|    Iris-setosa|             -1|\n",
      "|        4.4|       2.9|        1.4|       0.2|    Iris-setosa|             -1|\n",
      "|        4.4|       3.0|        1.3|       0.2|    Iris-setosa|             -1|\n",
      "|        4.4|       3.2|        1.3|       0.2|    Iris-setosa|             -1|\n",
      "|        4.5|       2.3|        1.3|       0.3|    Iris-setosa|             -1|\n",
      "|        4.6|       3.1|        1.5|       0.2|    Iris-setosa|             -1|\n",
      "|        4.6|       3.2|        1.4|       0.2|    Iris-setosa|             -1|\n",
      "|        4.6|       3.4|        1.4|       0.3|    Iris-setosa|             -1|\n",
      "|        4.6|       3.6|        1.0|       0.2|    Iris-setosa|             -1|\n",
      "|        4.7|       3.2|        1.3|       0.2|    Iris-setosa|             -1|\n",
      "|        4.7|       3.2|        1.6|       0.2|    Iris-setosa|             -1|\n",
      "|        4.8|       3.0|        1.4|       0.1|    Iris-setosa|             -1|\n",
      "|        4.8|       3.0|        1.4|       0.3|    Iris-setosa|             -1|\n",
      "|        4.8|       3.1|        1.6|       0.2|    Iris-setosa|             -1|\n",
      "|        4.8|       3.4|        1.6|       0.2|    Iris-setosa|             -1|\n",
      "|        4.8|       3.4|        1.9|       0.2|    Iris-setosa|             -1|\n",
      "|        4.9|       2.4|        3.3|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        4.9|       2.5|        4.5|       1.7| Iris-virginica| Iris-virginica|\n",
      "|        4.9|       3.0|        1.4|       0.2|    Iris-setosa|             -1|\n",
      "|        4.9|       3.1|        1.5|       0.1|    Iris-setosa|             -1|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.withColumn('New_name',check(testDF['Name'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|           Name|       New_name|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|        4.9|       2.4|        3.3|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        4.9|       2.5|        4.5|       1.7| Iris-virginica| Iris-virginica|\n",
      "|        5.0|       2.0|        3.5|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        5.0|       2.3|        3.3|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        5.1|       2.5|        3.0|       1.1|Iris-versicolor|Iris-versicolor|\n",
      "|        5.2|       2.7|        3.9|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.4|       3.0|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.3|        4.0|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.4|        3.7|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.4|        3.8|       1.1|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.5|        4.0|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.6|        4.4|       1.2|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.5|        3.9|       1.1|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.7|        4.2|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.8|        4.9|       2.0| Iris-virginica| Iris-virginica|\n",
      "|        5.6|       2.9|        3.6|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       3.0|        4.1|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       3.0|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.7|       2.5|        5.0|       2.0| Iris-virginica| Iris-virginica|\n",
      "|        5.7|       2.6|        3.5|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF2 = testDF.withColumn('New_name',check(testDF['Name'])).filter('New_name <> \"-1\"')\n",
    "\n",
    "testDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           Name|\n",
      "+---------------+\n",
      "| Iris-virginica|\n",
      "|Iris-versicolor|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF2.select('Name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================过滤行 filter ==================\n",
    "estDF2 = df.withColumn('New_name',check(testDF['Name'])).filter('New_name <> \"-1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|           Name|       New_name|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|        7.0|       3.2|        4.7|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        6.4|       3.2|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        6.9|       3.1|        4.9|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.3|        4.0|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.5|       2.8|        4.6|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.7|       2.8|        4.5|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.3|       3.3|        4.7|       1.6|Iris-versicolor|Iris-versicolor|\n",
      "|        4.9|       2.4|        3.3|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.6|       2.9|        4.6|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.2|       2.7|        3.9|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.0|       2.0|        3.5|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        5.9|       3.0|        4.2|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        6.0|       2.2|        4.0|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.1|       2.9|        4.7|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.9|        3.6|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.7|       3.1|        4.4|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       3.0|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.8|       2.7|        4.1|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.2|       2.2|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.5|        3.9|       1.1|Iris-versicolor|Iris-versicolor|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|SepalLength|SepalWidth|PetalLength|PetalWidth|           Name|       New_name|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "|        7.0|       3.2|        4.7|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        6.4|       3.2|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        6.9|       3.1|        4.9|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.5|       2.3|        4.0|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.5|       2.8|        4.6|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.7|       2.8|        4.5|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.3|       3.3|        4.7|       1.6|Iris-versicolor|Iris-versicolor|\n",
      "|        4.9|       2.4|        3.3|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.6|       2.9|        4.6|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        5.2|       2.7|        3.9|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.0|       2.0|        3.5|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        5.9|       3.0|        4.2|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        6.0|       2.2|        4.0|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.1|       2.9|        4.7|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.9|        3.6|       1.3|Iris-versicolor|Iris-versicolor|\n",
      "|        6.7|       3.1|        4.4|       1.4|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       3.0|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.8|       2.7|        4.1|       1.0|Iris-versicolor|Iris-versicolor|\n",
      "|        6.2|       2.2|        4.5|       1.5|Iris-versicolor|Iris-versicolor|\n",
      "|        5.6|       2.5|        3.9|       1.1|Iris-versicolor|Iris-versicolor|\n",
      "+-----------+----------+-----------+----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fun\n",
    "df.withColumn('New_name',check(testDF['Name'])).filter(fun.col('New_name')!=\"-1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
