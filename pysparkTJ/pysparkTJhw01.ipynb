{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pysparkTJhw01\n",
    "安装开发环境，写一个wordcount程序，并截屏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成SparkSession实例\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local[*]\") \\\n",
    "     .appName(\"Word Count\") \\\n",
    "     .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过sparkSession获取上下文\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.textFile(\"/test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pyspark.ml.linalg', 1),\n",
       " ('import', 3),\n",
       " ('Vectors', 1),\n",
       " ('LogisticRegression', 4),\n",
       " ('pyspark.sql', 1),\n",
       " ('=', 12),\n",
       " ('SparkSession.builder.master(\"spark://h1:7077\").appName(\"test\").getOrCreate()',\n",
       "  1),\n",
       " ('#', 20),\n",
       " ('training', 2),\n",
       " ('of', 2),\n",
       " ('features)', 1),\n",
       " ('(1.0,', 4),\n",
       " ('Vectors.dense([0.0,', 3),\n",
       " ('1.1,', 1),\n",
       " ('0.1])),', 1),\n",
       " ('Vectors.dense([2.0,', 2),\n",
       " ('1.0,', 1),\n",
       " ('-1.0])),', 1),\n",
       " ('1.3,', 1),\n",
       " ('1.0])),', 1),\n",
       " ('1.2,', 1),\n",
       " ('-0.5]))],', 1),\n",
       " ('[\"label\",', 2),\n",
       " ('Create', 1),\n",
       " ('instance.', 2),\n",
       " ('is', 2),\n",
       " ('an', 2),\n",
       " ('lr', 1),\n",
       " ('regParam=0.01)', 1),\n",
       " ('Print', 1),\n",
       " ('out', 1),\n",
       " ('parameters,', 1),\n",
       " ('default', 1),\n",
       " ('print(\"LogisticRegression', 1),\n",
       " ('lr.explainParams()', 1),\n",
       " ('\"\\\\n\")', 1),\n",
       " ('Learn', 1),\n",
       " ('uses', 1),\n",
       " ('stored', 1),\n",
       " ('in', 2),\n",
       " ('model1', 2),\n",
       " ('lr.fit(training)', 1),\n",
       " ('Since', 1),\n",
       " ('produced', 1),\n",
       " ('Estimator),', 1),\n",
       " ('we', 2),\n",
       " ('used', 1),\n",
       " ('during', 1),\n",
       " ('parameter', 2),\n",
       " ('value)', 1),\n",
       " ('where', 1),\n",
       " ('names', 1),\n",
       " ('are', 2),\n",
       " ('this', 1),\n",
       " ('1', 2),\n",
       " ('was', 2),\n",
       " ('using', 5),\n",
       " ('parameters:', 2),\n",
       " ('print(model1.extractParamMap())', 1),\n",
       " ('may', 1),\n",
       " ('alternatively', 1),\n",
       " ('Python', 1),\n",
       " ('dictionary', 1),\n",
       " ('as', 1),\n",
       " ('{lr.maxIter:', 1),\n",
       " ('Specify', 2),\n",
       " ('overwriting', 1),\n",
       " ('paramMap.update({lr.regParam:', 1),\n",
       " ('multiple', 1),\n",
       " ('Params.', 1),\n",
       " ('combine', 1),\n",
       " ('python', 1),\n",
       " ('Change', 1),\n",
       " ('output', 1),\n",
       " ('column', 3),\n",
       " ('name', 1),\n",
       " ('paramMapCombined', 3),\n",
       " ('paramMapCombined.update(paramMap2)', 1),\n",
       " ('Now', 1),\n",
       " ('new', 1),\n",
       " ('model', 1),\n",
       " ('overrides', 1),\n",
       " ('set', 1),\n",
       " ('via', 1),\n",
       " ('methods.', 1),\n",
       " ('lr.fit(training,', 1),\n",
       " ('paramMapCombined)', 1),\n",
       " ('print(model2.extractParamMap())', 1),\n",
       " ('test', 3),\n",
       " ('predictions', 1),\n",
       " ('LogisticRegression.transform', 1),\n",
       " ('only', 1),\n",
       " ('use', 1),\n",
       " ('column.', 1),\n",
       " ('Note', 1),\n",
       " ('\"myProbability\"', 1),\n",
       " ('instead', 1),\n",
       " ('usual', 1),\n",
       " ('renamed', 1),\n",
       " ('lr.probabilityCol', 1),\n",
       " ('prediction', 1),\n",
       " ('model2.transform(test)', 1),\n",
       " ('result', 1),\n",
       " ('prediction.select(\"features\",', 1),\n",
       " ('\"myProbability\",', 1),\n",
       " ('\"prediction\")', 1),\n",
       " ('.collect()', 1),\n",
       " ('row', 1),\n",
       " ('result:', 1),\n",
       " ('print(\"features=%s,', 1),\n",
       " ('label=%s', 1),\n",
       " ('prob=%s,', 1),\n",
       " ('prediction=%s\"', 1),\n",
       " ('row.label,', 1),\n",
       " ('from', 4),\n",
       " ('pyspark.ml.classification', 1),\n",
       " ('SparkSession', 1),\n",
       " ('spark', 1),\n",
       " ('Prepare', 2),\n",
       " ('data', 3),\n",
       " ('a', 9),\n",
       " ('list', 1),\n",
       " ('(label,', 1),\n",
       " ('tuples.', 1),\n",
       " ('spark.createDataFrame([', 2),\n",
       " ('(0.0,', 3),\n",
       " ('\"features\"])', 2),\n",
       " ('This', 3),\n",
       " ('instance', 1),\n",
       " ('Estimator.', 1),\n",
       " ('LogisticRegression(maxIter=10,', 1),\n",
       " ('the', 10),\n",
       " ('documentation,', 1),\n",
       " ('and', 1),\n",
       " ('any', 1),\n",
       " ('values.', 1),\n",
       " ('parameters:\\\\n\"', 1),\n",
       " ('+', 2),\n",
       " ('model.', 1),\n",
       " ('parameters', 4),\n",
       " ('lr.', 1),\n",
       " ('Model', 1),\n",
       " ('(i.e.,', 1),\n",
       " ('transformer', 1),\n",
       " ('by', 1),\n",
       " ('can', 2),\n",
       " ('view', 1),\n",
       " ('it', 1),\n",
       " ('fit().', 1),\n",
       " ('prints', 1),\n",
       " ('(name:', 1),\n",
       " ('pairs,', 1),\n",
       " ('unique', 1),\n",
       " ('IDs', 1),\n",
       " ('for', 2),\n",
       " ('print(\"Model', 2),\n",
       " ('fit', 2),\n",
       " ('\")', 2),\n",
       " ('We', 1),\n",
       " ('specify', 1),\n",
       " ('paramMap', 2),\n",
       " ('20}', 1),\n",
       " ('paramMap[lr.maxIter]', 1),\n",
       " ('30', 1),\n",
       " ('Param,', 1),\n",
       " ('original', 1),\n",
       " ('maxIter.', 1),\n",
       " ('0.1,', 1),\n",
       " ('lr.threshold:', 1),\n",
       " ('0.55})', 1),\n",
       " ('You', 1),\n",
       " ('paramMaps,', 1),\n",
       " ('which', 1),\n",
       " ('dictionaries.', 1),\n",
       " ('paramMap2', 1),\n",
       " ('{lr.probabilityCol:', 1),\n",
       " ('\"myProbability\"}', 1),\n",
       " ('paramMap.copy()', 1),\n",
       " ('learn', 1),\n",
       " ('parameters.', 1),\n",
       " ('all', 1),\n",
       " ('earlier', 1),\n",
       " ('lr.set*', 1),\n",
       " ('model2', 1),\n",
       " ('2', 1),\n",
       " ('Vectors.dense([-1.0,', 1),\n",
       " ('1.5,', 1),\n",
       " ('1.3])),', 1),\n",
       " ('Vectors.dense([3.0,', 1),\n",
       " ('2.0,', 1),\n",
       " ('-0.1])),', 1),\n",
       " ('2.2,', 1),\n",
       " ('-1.5]))],', 1),\n",
       " ('Make', 1),\n",
       " ('on', 1),\n",
       " ('Transformer.transform()', 1),\n",
       " ('method.', 1),\n",
       " ('will', 1),\n",
       " (\"'features'\", 1),\n",
       " ('that', 1),\n",
       " ('model2.transform()', 1),\n",
       " ('outputs', 1),\n",
       " (\"'probability'\", 1),\n",
       " ('since', 1),\n",
       " ('previously.', 1),\n",
       " ('\"label\",', 1),\n",
       " ('\\\\', 1),\n",
       " ('->', 1),\n",
       " ('%', 1),\n",
       " ('(row.features,', 1),\n",
       " ('row.myProbability,', 1),\n",
       " ('row.prediction))', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rdd1.flatMap(lambda x:x.split())\\\n",
    "        .map(lambda x:(x,1))\\\n",
    "        .reduceByKey(lambda a,b: a+b)\\\n",
    "        .collect()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
